{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6086f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "import shap\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader, Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(540),         # 짧은 변을 540으로\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "data_root = '/home/work/workspace_ai/Artificlass/data_process/data/augmented_images_4'\n",
    "full_dataset = datasets.ImageFolder(root=data_root, transform=None)\n",
    "# train_ds = ImageFolder(root=data_root, transform=train_transform)\n",
    "# val_ds   = ImageFolder(root=data_root, transform=val_transform)\n",
    "style2idx   = full_dataset.class_to_idx.copy()\n",
    "num_classes = len(style2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(full_dataset)\n",
    "indices = np.arange(n)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "train_idx = indices[:n_train]\n",
    "val_idx   = indices[n_train:n_train+n_val]\n",
    "test_idx  = indices[n_train+n_val:]\n",
    "\n",
    "test_ds  = Subset(datasets.ImageFolder(root=data_root, transform=val_transform),\n",
    "                  test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f9790",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_kwargs = dict(\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader  = DataLoader(test_ds,  shuffle=False, **loader_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Head(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet50(pretrained=False)\n",
    "        in_feats  = backbone.fc.in_features\n",
    "        backbone.fc = nn.Identity()\n",
    "        self.backbone = backbone\n",
    "\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.fc1  = nn.Linear(in_feats, 512)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2  = nn.Linear(512, 128)\n",
    "        self.fc3  = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)        # → (batch, 2048)\n",
    "        x = self.drop(x)\n",
    "        x = self.relu(self.fc1(x))  # → (batch, 1024)\n",
    "        x = self.drop(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(x)             # → (batch, num_classes)\n",
    "        return x\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model  = ResNet50Head(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6540e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model load \n",
    "\n",
    "model_path='/home/work/workspace_ai/Artificlass/real_use_code/best_model_from_folder_pre.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f0086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import shap\n",
    "\n",
    "# 1) 모델 불러오기\n",
    "from backbone import ResNet50Head  # 실제 정의한 모듈 경로 맞춰주세요\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# data_root = '/home/work/workspace_ai/Artificlass/data_process/data/augmented_images_4'\n",
    "# full_dataset = datasets.ImageFolder(root=data_root, transform=None)\n",
    "# # train_ds = ImageFolder(root=data_root, transform=train_transform)\n",
    "# # val_ds   = ImageFolder(root=data_root, transform=val_transform)\n",
    "# style2idx   = full_dataset.class_to_idx.copy()\n",
    "style2idx = {'Art Nouveau': 0, 'Baroque': 1, 'Expressionism': 2, 'Impressionism': 3, 'Post-Impressionism': 4, 'Realism': 5, 'Romantic': 6}\n",
    "idx2style = {i:s for s,i in style2idx.items()}\n",
    "num_classes = len(style2idx)\n",
    "model = ResNet50Head(num_classes).to(device)\n",
    "model.load_state_dict(torch.load('best_model_from_folder_pre.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 2) SHAP 입력용 normalize 함수\n",
    "mean = np.array([0.485, 0.456, 0.406]).reshape((1,1,3))\n",
    "std  = np.array([0.229, 0.224, 0.225]).reshape((1,1,3))\n",
    "def preprocess(imgs):\n",
    "    # imgs: numpy (B,H,W,3) in [0,1] or [0,255]\n",
    "    if imgs.max() > 1.0:\n",
    "        imgs = imgs / 255.0\n",
    "    imgs = (imgs - mean) / std\n",
    "    # B,H,W,3 → B,3,H,W\n",
    "    return torch.from_numpy(imgs).permute(0,3,1,2).float().to(device)\n",
    "\n",
    "# 3) 배경용(Background) 데이터 샘플\n",
    "#    전체 테스트셋에서 랜덤하게 50장 정도 뽑아서 numpy array로 준비\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize(540),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor()  # → [0,1], C×H×W\n",
    "])\n",
    "\n",
    "ds = ImageFolder(root='/home/work/workspace_ai/Artificlass/data_process/data/augmented_images_4',\n",
    "                 transform=val_tf)\n",
    "# 뒤에서 numpy로 바꾸려면 tensor→numpy\n",
    "bg_indices = np.random.choice(len(ds), size=50, replace=False)\n",
    "bg_imgs = []\n",
    "for idx in bg_indices:\n",
    "    img, _ = ds[idx]                # img: Tensor(3,512,512)\n",
    "    bg_imgs.append(img.permute(1,2,0).numpy())  # H×W×C\n",
    "bg_imgs = np.stack(bg_imgs, axis=0)  # (50,H,W,C)\n",
    "\n",
    "# 4) 설명할 샘플 선택 (예: 2장)\n",
    "to_explain = []\n",
    "for idx in [10, 23]:\n",
    "    img, _ = ds[idx]\n",
    "    to_explain.append(img.permute(1,2,0).numpy())\n",
    "to_explain = np.stack(to_explain, axis=0)  # (2,H,W,C)\n",
    "\n",
    "# 5) GradientExplainer 생성\n",
    "#    두 번째 인자는 ‘모델-출력-전’ 레이어를 지정할 수도 있지만,\n",
    "#    전체 모델에 대해 입력 그라디언트 기반 설명을 원하면 (model, model.backbone) 처럼 전달\n",
    "explainer = shap.GradientExplainer(\n",
    "    (model, model.backbone),       # 또는 (model, model.backbone.layer4)\n",
    "    preprocess(bg_imgs)            # background as Tensor(50,3,512,512)\n",
    ")\n",
    "\n",
    "# 6) SHAP 값 계산\n",
    "#    ranked_outputs=1 → 가장 높은 클래스에 대한 explanation\n",
    "shap_values, indexes = explainer.shap_values(\n",
    "    preprocess(to_explain),       # Tensor(2,3,512,512)\n",
    "    ranked_outputs=1,\n",
    "    nsamples=100                   # 조절 가능\n",
    ")\n",
    "\n",
    "# 7) 클래스 이름 로드 (imagenet_class_index.json 필요)\n",
    "# with open('imagenet_class_index.json') as f:\n",
    "#     class_idx = json.load(f)\n",
    "# # index → 이름 매핑\n",
    "# idx_to_name = {int(k):v[1] for k,v in class_idx.items()}\n",
    "# index_names = np.array([[ idx_to_name[i] for i in idx_list ]\n",
    "#                         for idx_list in indexes])\n",
    "index_names = np.array([\n",
    "    [ idx2style[i] for i in idx_list ]\n",
    "    for idx_list in indexes\n",
    "])\n",
    "\n",
    "# 8) 시각화\n",
    "#    shap_values: list of arrays [ for each output-class: (2,3,512,512) ]\n",
    "#    to_explain:      (2,512,512,3)\n",
    "#    index_names:     (2,1)\n",
    "shap_values = [ sv.transpose(0,2,3,1) for sv in shap_values ]\n",
    "shap.image_plot(shap_values, to_explain, index_names)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
